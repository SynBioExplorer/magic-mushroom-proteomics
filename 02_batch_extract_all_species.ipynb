{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Protein Extraction - All Species\n",
    "\n",
    "**Goal:** Extract all 4 BGC proteins (PsiD, PsiK, PsiM, PsiH) from all 71 Psilocybe species\n",
    "\n",
    "**Input:** \n",
    "- 71 genome scaffold files from `03_Sequences_Paper/Assembly_scaffolds/`\n",
    "- 4 reference proteins (PsiD, PsiK, PsiM, PsiH) from P. cubensis\n",
    "\n",
    "**Output:**\n",
    "- ~284 protein sequences (71 species × 4 genes)\n",
    "- Combined FASTA files for each gene (for phylogenetic analysis)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set paths\n",
    "PROJECT_DIR = Path.cwd().parent\n",
    "SCAFFOLD_DIR = PROJECT_DIR / \"03_Sequences_Paper\" / \"Assembly_scaffolds\"\n",
    "REF_PROTEIN_DIR = Path.cwd() / \"reference_proteins\"\n",
    "INPUT_DIR = PROJECT_DIR / \"01_Colab_codes_InputFiles\" / \"Files_paper_P_baeocystis\"\n",
    "\n",
    "# Create output directories\n",
    "BATCH_RESULTS_DIR = Path.cwd() / \"batch_results\"\n",
    "BATCH_RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Create subdirectories for each gene\n",
    "for gene in ['PsiD', 'PsiK', 'PsiM', 'PsiH']:\n",
    "    (BATCH_RESULTS_DIR / gene).mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Scaffold directory: {SCAFFOLD_DIR}\")\n",
    "print(f\"Results directory: {BATCH_RESULTS_DIR}\")\n",
    "print(f\"Reference proteins: {REF_PROTEIN_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define BGC Genes and Reference Proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all 4 BGC genes with their reference proteins\n",
    "BGC_GENES = {\n",
    "    'PsiD': {\n",
    "        'name': 'Tryptophan decarboxylase',\n",
    "        'reference': INPUT_DIR / \"PsiD_Psilocybe_cubensis_reference.faa\",\n",
    "        'function': 'Converts tryptophan to tryptamine'\n",
    "    },\n",
    "    'PsiK': {\n",
    "        'name': 'Kinase',\n",
    "        'reference': REF_PROTEIN_DIR / \"PsiK_Psilocybe_cubensis_reference.faa\",\n",
    "        'function': 'Phosphorylates intermediate'\n",
    "    },\n",
    "    'PsiM': {\n",
    "        'name': 'Methyltransferase',\n",
    "        'reference': REF_PROTEIN_DIR / \"PsiM_Psilocybe_cubensis_reference.faa\",\n",
    "        'function': 'Methylates tryptamine'\n",
    "    },\n",
    "    'PsiH': {\n",
    "        'name': 'P450 monooxygenase',\n",
    "        'reference': REF_PROTEIN_DIR / \"PsiH_Psilocybe_cubensis_reference.faa\",\n",
    "        'function': 'Hydroxylates at C-4 position (critical for activity)'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Verify all reference files exist\n",
    "print(\"Checking reference protein files:\")\n",
    "for gene, info in BGC_GENES.items():\n",
    "    exists = info['reference'].exists()\n",
    "    symbol = \"✅\" if exists else \"❌\"\n",
    "    print(f\"  {symbol} {gene}: {info['reference'].name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List All Species Scaffolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all scaffold files\n",
    "scaffold_files = sorted(list(SCAFFOLD_DIR.glob(\"*.scaffolds.fasta\")))\n",
    "\n",
    "print(f\"Found {len(scaffold_files)} species scaffold files\\n\")\n",
    "print(\"First 10 species:\")\n",
    "for i, scaffold_file in enumerate(scaffold_files[:10], 1):\n",
    "    species_name = scaffold_file.stem.replace('.scaffolds', '')\n",
    "    print(f\"  {i}. {species_name}\")\n",
    "    \n",
    "print(f\"\\n... and {len(scaffold_files) - 10} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_protein(species_name, scaffold_file, gene, reference_protein, output_dir, verbose=False):\n",
    "    \"\"\"\n",
    "    Extract a single protein from a genome scaffold.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Results with status, protein length, and any warnings\n",
    "    \"\"\"\n",
    "    # Define output files\n",
    "    output_cds = output_dir / f\"{species_name}_{gene}.cds.fa\"\n",
    "    output_protein = output_dir / f\"{species_name}_{gene}.prot.fa\"\n",
    "    \n",
    "    results = {\n",
    "        'species': species_name,\n",
    "        'gene': gene,\n",
    "        'status': 'pending',\n",
    "        'protein_length': 0,\n",
    "        'stop_codons': 0,\n",
    "        'warnings': []\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Extract CDS with exonerate\n",
    "        cmd_cds = f'''exonerate --model protein2genome \\\n",
    "  \"{reference_protein}\" \\\n",
    "  \"{scaffold_file}\" \\\n",
    "  --bestn 1 \\\n",
    "  --showalignment no --showvulgar no --verbose 0 \\\n",
    "  --ryo \">{gene}|%ti:%tab-%tae(%tS)\\\\n%tcs\\\\n\" > \"{output_cds}\"'''\n",
    "        \n",
    "        result = subprocess.run(cmd_cds, shell=True, capture_output=True, text=True, timeout=300)\n",
    "        \n",
    "        if result.returncode != 0:\n",
    "            results['status'] = 'failed_exonerate'\n",
    "            results['warnings'].append(f\"Exonerate failed: {result.stderr[:100]}\")\n",
    "            return results\n",
    "        \n",
    "        # Check if CDS was found\n",
    "        if not output_cds.exists() or output_cds.stat().st_size == 0:\n",
    "            results['status'] = 'no_match'\n",
    "            results['warnings'].append(\"No match found in genome\")\n",
    "            return results\n",
    "        \n",
    "        # Step 2: Translate to protein\n",
    "        cmd_translate = f'transeq -sequence \"{output_cds}\" -outseq \"{output_protein}\" -frame 1'\n",
    "        result = subprocess.run(cmd_translate, shell=True, capture_output=True, text=True, timeout=60)\n",
    "        \n",
    "        if result.returncode != 0:\n",
    "            results['status'] = 'failed_translate'\n",
    "            results['warnings'].append(f\"Translation failed: {result.stderr[:100]}\")\n",
    "            return results\n",
    "        \n",
    "        # Step 3: Quality control\n",
    "        if output_protein.exists():\n",
    "            record = list(SeqIO.parse(output_protein, \"fasta\"))[0]\n",
    "            sequence = str(record.seq)\n",
    "            \n",
    "            # Check for internal stop codons\n",
    "            internal_seq = sequence[:-1] if sequence.endswith('*') else sequence\n",
    "            stop_count = internal_seq.count('*')\n",
    "            \n",
    "            results['protein_length'] = len(sequence)\n",
    "            results['stop_codons'] = stop_count\n",
    "            \n",
    "            if stop_count > 0:\n",
    "                results['warnings'].append(f\"{stop_count} internal stop codon(s)\")\n",
    "            \n",
    "            if len(sequence) < 50:\n",
    "                results['warnings'].append(f\"Protein very short: {len(sequence)} aa\")\n",
    "            \n",
    "            results['status'] = 'success'\n",
    "        else:\n",
    "            results['status'] = 'failed_qc'\n",
    "            results['warnings'].append(\"Protein file not created\")\n",
    "    \n",
    "    except subprocess.TimeoutExpired:\n",
    "        results['status'] = 'timeout'\n",
    "        results['warnings'].append(\"Command timeout\")\n",
    "    except Exception as e:\n",
    "        results['status'] = 'error'\n",
    "        results['warnings'].append(f\"Exception: {str(e)[:100]}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"✓ Extraction function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on a Few Species First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on first 3 species\n",
    "test_species = scaffold_files[:3]\n",
    "\n",
    "print(\"Testing extraction on 3 species...\\n\")\n",
    "test_results = []\n",
    "\n",
    "for scaffold_file in test_species:\n",
    "    species_name = scaffold_file.stem.replace('.scaffolds', '')\n",
    "    print(f\"Processing: {species_name}\")\n",
    "    \n",
    "    for gene, info in BGC_GENES.items():\n",
    "        output_dir = BATCH_RESULTS_DIR / gene\n",
    "        result = extract_protein(\n",
    "            species_name=species_name,\n",
    "            scaffold_file=scaffold_file,\n",
    "            gene=gene,\n",
    "            reference_protein=info['reference'],\n",
    "            output_dir=output_dir\n",
    "        )\n",
    "        test_results.append(result)\n",
    "        \n",
    "        status_symbol = \"✅\" if result['status'] == 'success' else \"⚠️\"\n",
    "        print(f\"  {status_symbol} {gene}: {result['status']} ({result['protein_length']} aa)\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "# Show summary\n",
    "df_test = pd.DataFrame(test_results)\n",
    "print(\"\\nTest Summary:\")\n",
    "print(df_test[['species', 'gene', 'status', 'protein_length']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Process All Species\n",
    "\n",
    "**Note:** This will take some time (~71 species × 4 genes = 284 extractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all species\n",
    "all_results = []\n",
    "\n",
    "print(f\"Processing {len(scaffold_files)} species × 4 genes = {len(scaffold_files) * 4} extractions\\n\")\n",
    "\n",
    "for scaffold_file in tqdm(scaffold_files, desc=\"Species\"):\n",
    "    species_name = scaffold_file.stem.replace('.scaffolds', '')\n",
    "    \n",
    "    for gene, info in BGC_GENES.items():\n",
    "        output_dir = BATCH_RESULTS_DIR / gene\n",
    "        result = extract_protein(\n",
    "            species_name=species_name,\n",
    "            scaffold_file=scaffold_file,\n",
    "            gene=gene,\n",
    "            reference_protein=info['reference'],\n",
    "            output_dir=output_dir,\n",
    "            verbose=False\n",
    "        )\n",
    "        all_results.append(result)\n",
    "\n",
    "print(\"\\n✓ Batch extraction complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary DataFrame\n",
    "df_results = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"BATCH EXTRACTION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Overall stats\n",
    "print(f\"\\nTotal extractions: {len(df_results)}\")\n",
    "print(f\"Successful: {len(df_results[df_results['status'] == 'success'])}\")\n",
    "print(f\"Failed: {len(df_results[df_results['status'] != 'success'])}\")\n",
    "\n",
    "# Stats by gene\n",
    "print(\"\\nSuccess rate by gene:\")\n",
    "for gene in ['PsiD', 'PsiK', 'PsiM', 'PsiH']:\n",
    "    gene_data = df_results[df_results['gene'] == gene]\n",
    "    success_count = len(gene_data[gene_data['status'] == 'success'])\n",
    "    total = len(gene_data)\n",
    "    pct = (success_count / total * 100) if total > 0 else 0\n",
    "    print(f\"  {gene}: {success_count}/{total} ({pct:.1f}%)\")\n",
    "\n",
    "# Protein length statistics\n",
    "print(\"\\nProtein length statistics (successful extractions):\")\n",
    "success_df = df_results[df_results['status'] == 'success']\n",
    "for gene in ['PsiD', 'PsiK', 'PsiM', 'PsiH']:\n",
    "    gene_data = success_df[success_df['gene'] == gene]['protein_length']\n",
    "    if len(gene_data) > 0:\n",
    "        print(f\"  {gene}: mean={gene_data.mean():.0f} aa, min={gene_data.min()}, max={gene_data.max()}\")\n",
    "\n",
    "# Show failures\n",
    "failed_df = df_results[df_results['status'] != 'success']\n",
    "if len(failed_df) > 0:\n",
    "    print(f\"\\nFailed extractions ({len(failed_df)}):\")\n",
    "    print(failed_df[['species', 'gene', 'status']].head(10).to_string(index=False))\n",
    "    if len(failed_df) > 10:\n",
    "        print(f\"... and {len(failed_df) - 10} more\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Save results to CSV\n",
    "results_csv = BATCH_RESULTS_DIR / \"extraction_summary.csv\"\n",
    "df_results.to_csv(results_csv, index=False)\n",
    "print(f\"\\nResults saved to: {results_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Proteins by Gene\n",
    "\n",
    "Create combined FASTA files for each gene (all species together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Combining proteins by gene...\\n\")\n",
    "\n",
    "for gene in ['PsiD', 'PsiK', 'PsiM', 'PsiH']:\n",
    "    gene_dir = BATCH_RESULTS_DIR / gene\n",
    "    combined_file = BATCH_RESULTS_DIR / f\"{gene}_all_species.faa\"\n",
    "    \n",
    "    # Collect all successful protein files\n",
    "    protein_files = sorted(gene_dir.glob(\"*_prot.fa\"))\n",
    "    \n",
    "    combined_records = []\n",
    "    for prot_file in protein_files:\n",
    "        try:\n",
    "            record = list(SeqIO.parse(prot_file, \"fasta\"))[0]\n",
    "            # Update ID to include species name\n",
    "            species_name = prot_file.stem.replace(f\"_{gene}.prot\", \"\")\n",
    "            record.id = f\"{species_name}|{gene}\"\n",
    "            record.description = f\"{gene} [{species_name}]\"\n",
    "            combined_records.append(record)\n",
    "        except:\n",
    "            pass  # Skip files that can't be read\n",
    "    \n",
    "    # Write combined file\n",
    "    SeqIO.write(combined_records, combined_file, \"fasta\")\n",
    "    print(f\"✓ {gene}: {len(combined_records)} sequences → {combined_file.name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BATCH PROCESSING COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nResults location: {BATCH_RESULTS_DIR}\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"  1. Review extraction_summary.csv for success rates\")\n",
    "print(\"  2. Use *_all_species.faa files for multiple sequence alignment (MAFFT)\")\n",
    "print(\"  3. Build phylogenetic trees (IQ-TREE)\")\n",
    "print(\"  4. Perform ancestral sequence reconstruction (ASR)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
